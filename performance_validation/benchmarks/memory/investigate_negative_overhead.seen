// Seen Language Memory Overhead Investigation
// Investigates the impossible "-58% memory overhead" claim
// This benchmark will find what's actually being measured and provide honest results

use std.memory
use std.benchmark
use std.collections
use std.time
use std.random

@benchmark
fun investigateMemoryClaim(b: Bencher) {
    // The "-58% memory overhead" claim is physically impossible
    // This benchmark will find what's actually being measured
    
    println("=== Investigating Memory Overhead Claims ===")
    println("Note: Negative memory overhead is mathematically impossible")
    println("This test will find what metrics are actually being compared\n")
    
    // Test 1: Allocation patterns with different sizes
    val allocSizes = listOf(8, 64, 1024, 8192, 65536)
    for (size in allocSizes) {
        b.measure("allocation_overhead_${size}bytes") {
            val objects = mutableListOf<ByteArray>()
            val baselineMemory = memory.getUsedMemory()
            
            // Allocate 10,000 objects of specified size
            for (i in 0..9999) {
                objects.add(ByteArray(size))
            }
            
            val actualMemoryUsed = memory.getUsedMemory() - baselineMemory
            val requestedMemory = size * 10000L
            val overhead = (actualMemoryUsed - requestedMemory).toDouble() / requestedMemory
            
            b.recordMetric("overhead_percent_size_$size", overhead * 100)
            b.recordMetric("actual_memory_used_$size", actualMemoryUsed.toDouble())
            b.recordMetric("requested_memory_$size", requestedMemory.toDouble())
            
            // Force cleanup
            objects.clear()
            memory.forceGC()
        }
    }
    
    // Test 2: Compare with equivalent C malloc/free behavior
    compareWithCMalloc(b)
    
    // Test 3: Measure fragmentation over time
    measureFragmentation(b)
    
    // Test 4: Different allocation patterns
    testAllocationPatterns(b)
}

@benchmark
fun compareWithCMalloc(b: Bencher) {
    // Compare Seen's memory allocator with C's malloc/free
    println("Comparing with C malloc/free behavior...")
    
    val testSizes = listOf(16, 128, 1024, 4096)
    
    for (size in testSizes) {
        // Seen allocation
        b.measure("seen_alloc_${size}bytes") {
            val objects = mutableListOf<ByteArray>()
            for (i in 0..999) {
                objects.add(ByteArray(size))
            }
            // Measure actual memory used
            val memUsed = memory.getPeakMemoryUsage()
            b.recordMetric("seen_memory_${size}", memUsed.toDouble())
        }
        
        // C malloc simulation (using native calls if available)
        b.measure("c_malloc_simulation_${size}bytes") {
            // This would call actual C malloc/free for comparison
            val cMemUsed = simulateCMalloc(size, 1000)
            b.recordMetric("c_memory_${size}", cMemUsed.toDouble())
        }
        
        // Calculate actual overhead
        val seenMem = b.getMetric("seen_memory_${size}").mean()
        val cMem = b.getMetric("c_memory_${size}").mean()
        val actualOverhead = (seenMem - cMem) / cMem * 100
        
        println("Size ${size}B: Seen=${seenMem / 1024:.1f}KB, C=${cMem / 1024:.1f}KB, Overhead=${actualOverhead:.1f}%")
        
        if (actualOverhead < 0) {
            println("⚠️  WARNING: Negative overhead detected - investigation needed")
        }
    }
}

@benchmark
fun measureFragmentation(b: Bencher) {
    // Measure memory fragmentation over time
    println("Measuring memory fragmentation patterns...")
    
    b.measure("fragmentation_test") {
        val allocatedObjects = mutableListOf<ByteArray>()
        val fragmentationMetrics = mutableListOf<Double>()
        
        // Phase 1: Allocate many small objects
        for (i in 0..4999) {
            val size = Random.nextInt(16, 256)
            allocatedObjects.add(ByteArray(size))
            
            if (i % 500 == 0) {
                val fragmentation = memory.getFragmentationRatio()
                fragmentationMetrics.add(fragmentation)
                b.recordMetric("fragmentation_at_${i}_allocs", fragmentation)
            }
        }
        
        // Phase 2: Deallocate every other object (create holes)
        for (i in allocatedObjects.indices step 2) {
            allocatedObjects[i] = ByteArray(0) // Release reference
        }
        memory.forceGC()
        
        val midFragmentation = memory.getFragmentationRatio()
        b.recordMetric("fragmentation_after_partial_dealloc", midFragmentation)
        
        // Phase 3: Try to allocate large objects (test fragmentation impact)
        val largeAllocSuccess = mutableListOf<Boolean>()
        for (i in 0..99) {
            try {
                val largeObject = ByteArray(8192)
                largeAllocSuccess.add(true)
            } catch (e: OutOfMemoryError) {
                largeAllocSuccess.add(false)
            }
        }
        
        val successRate = largeAllocSuccess.count { it }.toDouble() / largeAllocSuccess.size
        b.recordMetric("large_alloc_success_rate_after_fragmentation", successRate * 100)
        
        println("Fragmentation analysis:")
        println("  Initial: ${fragmentationMetrics.first():.3f}")
        println("  After partial dealloc: ${midFragmentation:.3f}")
        println("  Large alloc success: ${successRate * 100:.1f}%")
    }
}

@benchmark
fun testAllocationPatterns(b: Bencher) {
    // Test different allocation patterns that might explain the claim
    
    // Pattern 1: Pool allocator behavior
    b.measure("pool_allocation_pattern") {
        val pools = mutableMapOf<Int, MutableList<ByteArray>>()
        val commonSizes = listOf(8, 16, 32, 64, 128, 256, 512, 1024)
        
        // Pre-allocate pools
        for (size in commonSizes) {
            pools[size] = mutableListOf()
            for (i in 0..99) {
                pools[size]!!.add(ByteArray(size))
            }
        }
        
        val poolMemory = memory.getUsedMemory()
        
        // Use from pools (should have minimal overhead)
        var totalAllocated = 0L
        for (i in 0..999) {
            val size = commonSizes.random()
            val pool = pools[size]!!
            if (pool.isNotEmpty()) {
                val obj = pool.removeAt(pool.size - 1)
                totalAllocated += size
                // Simulate using the object
                obj.fill(i.toByte())
            }
        }
        
        b.recordMetric("pool_memory_efficiency", totalAllocated.toDouble() / poolMemory)
    }
    
    // Pattern 2: Stack allocation simulation
    b.measure("stack_like_allocation") {
        val baseMemory = memory.getUsedMemory()
        
        // Simulate stack-like allocation patterns
        allocateStackLike(1000)
        
        val stackMemory = memory.getUsedMemory() - baseMemory
        b.recordMetric("stack_like_memory_usage", stackMemory.toDouble())
    }
    
    // Pattern 3: Shared object patterns
    b.measure("shared_object_patterns") {
        val sharedStrings = listOf("common", "shared", "data", "value", "item")
        val objects = mutableListOf<String>()
        
        val baseMemory = memory.getUsedMemory()
        
        // Many objects sharing the same string instances
        for (i in 0..9999) {
            objects.add(sharedStrings.random())
        }
        
        val sharedMemory = memory.getUsedMemory() - baseMemory
        val individualMemory = objects.size * 32L // Approximate per-string memory
        val sharingEfficiency = (individualMemory - sharedMemory).toDouble() / individualMemory
        
        b.recordMetric("string_sharing_efficiency", sharingEfficiency * 100)
        
        if (sharingEfficiency > 0.5) {
            println("✓ String interning provides ${sharingEfficiency * 100:.1f}% memory savings")
        }
    }
}

fun simulateCMalloc(size: Int, count: Int): Long {
    // Simulate C malloc behavior for comparison
    // In a real implementation, this would use JNI to call actual malloc/free
    
    // Rough approximation: C malloc typically adds 8-16 bytes overhead per allocation
    val cOverheadPerAlloc = 12L
    val totalRequested = size.toLong() * count
    val totalWithCOverhead = totalRequested + (cOverheadPerAlloc * count)
    
    return totalWithCOverhead
}

fun allocateStackLike(depth: Int): Long {
    return if (depth <= 0) {
        0L
    } else {
        val localArray = ByteArray(64) // Simulate local variables
        localArray.fill(depth.toByte())
        localArray.size + allocateStackLike(depth - 1)
    }
}

@benchmark
fun investigateSpecificClaims(b: Bencher) {
    // Investigate what specific metrics might lead to a negative overhead claim
    
    println("Investigating possible explanations for negative overhead claim...")
    
    // Hypothesis 1: Measuring after vs before JIT compilation
    b.measure("jit_memory_difference") {
        val beforeJIT = memory.getUsedMemory()
        
        // Trigger JIT compilation with repeated operations
        for (i in 0..9999) {
            val data = ByteArray(100)
            data.sort()
        }
        
        val afterJIT = memory.getUsedMemory()
        val jitDifference = afterJIT - beforeJIT
        
        b.recordMetric("memory_change_after_jit", jitDifference.toDouble())
        
        if (jitDifference < 0) {
            println("📋 Possible explanation: JIT optimization reduces memory usage")
        }
    }
    
    // Hypothesis 2: Comparing with baseline that includes debug info
    b.measure("debug_vs_release_memory") {
        // This would compare memory usage in debug vs release builds
        val debugMemory = simulateDebugMemoryUsage()
        val releaseMemory = memory.getUsedMemory()
        
        val improvement = (debugMemory - releaseMemory).toDouble() / debugMemory * 100
        b.recordMetric("debug_to_release_improvement", improvement)
        
        println("Debug vs Release memory improvement: ${improvement:.1f}%")
    }
    
    // Hypothesis 3: Measuring virtual vs RSS memory
    b.measure("virtual_vs_rss_memory") {
        val virtualMem = memory.getVirtualMemoryUsage()
        val rssMem = memory.getResidentMemoryUsage()
        val difference = (virtualMem - rssMem).toDouble() / virtualMem * 100
        
        b.recordMetric("virtual_vs_rss_difference", difference)
        
        println("Virtual vs RSS memory difference: ${difference:.1f}%")
        if (difference > 50) {
            println("📋 Large difference between virtual and RSS - possible claim source")
        }
    }
}

fun simulateDebugMemoryUsage(): Long {
    // Simulate the additional memory that debug builds typically use
    val baseMemory = memory.getUsedMemory()
    return (baseMemory * 1.4).toLong() // Debug builds typically use ~40% more memory
}

// Main execution
fun main() {
    val bencher = Bencher(iterations = 30, warmupIterations = 5)
    
    println("=== Seen Memory Overhead Investigation ===")
    println("Investigating the claim of '-58% memory overhead'")
    println("Note: This is mathematically impossible - we'll find what's being measured\n")
    
    investigateMemoryClaim(bencher)
    investigateSpecificClaims(bencher)
    
    // Generate comprehensive analysis
    val results = bencher.getAllResults()
    analyzeMemoryResults(results)
    
    // Save results
    val report = bencher.generateReport()
    memory.saveToFile("../../results/memory_overhead_investigation.json", report.toJson())
    
    println("\n=== CONCLUSIONS ===")
    generateHonestMemoryReport(results)
}

fun analyzeMemoryResults(results: Map<String, BenchmarkResult>) {
    println("\n=== MEMORY ANALYSIS RESULTS ===")
    
    // Check if any test showed negative overhead
    var negativeOverheadFound = false
    var mostLikelyCause = "Unknown"
    
    for ((testName, result) in results) {
        if (testName.contains("overhead") && result.mean() < 0) {
            negativeOverheadFound = true
            println("⚠️  Negative overhead found in: $testName (${result.mean():.1f}%)")
        }
    }
    
    // Analyze possible causes
    val jitImprovement = results["memory_change_after_jit"]?.mean() ?: 0.0
    val debugImprovement = results["debug_to_release_improvement"]?.mean() ?: 0.0
    val sharingEfficiency = results["string_sharing_efficiency"]?.mean() ?: 0.0
    
    if (jitImprovement < 0) {
        mostLikelyCause = "JIT optimization reducing memory footprint"
    } else if (debugImprovement > 50) {
        mostLikelyCause = "Comparing against debug builds instead of optimized builds"
    } else if (sharingEfficiency > 50) {
        mostLikelyCause = "String/object interning providing significant savings"
    }
    
    println("\nMost likely explanation for negative overhead claim: $mostLikelyCause")
}

fun generateHonestMemoryReport(results: Map<String, BenchmarkResult>) {
    println("Based on comprehensive testing:")
    
    // Find actual overhead percentages
    val overheadTests = results.filter { it.key.contains("overhead_percent") }
    if (overheadTests.isNotEmpty()) {
        val avgOverhead = overheadTests.values.map { it.mean() }.average()
        
        if (avgOverhead < 0) {
            println("❌ CLAIM INVALID: Negative memory overhead is physically impossible")
            println("   Likely measuring against inappropriate baseline or including optimizations")
        } else if (avgOverhead < 10) {
            println("✅ EXCELLENT: Low memory overhead of ${avgOverhead:.1f}%")
        } else if (avgOverhead < 25) {
            println("✅ GOOD: Reasonable memory overhead of ${avgOverhead:.1f}%")
        } else {
            println("⚠️  HIGH: Memory overhead of ${avgOverhead:.1f}% may need optimization")
        }
    }
    
    println("\nRecommended honest claim: 'Seen provides efficient memory management")
    println("with X% overhead compared to manual C allocation'")
    println("\nWhere X is the actual measured overhead from these tests.")
}